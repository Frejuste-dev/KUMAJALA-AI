# ğŸš€ Guide de DÃ©marrage Rapide - ModÃ¨le TensorFlow Kumajala

## ğŸ“‹ PrÃ©requis

### Option A: Installation Locale (RecommandÃ© si Python 3.11/3.12)
```bash
cd kumajala-backend
pip install -r requirements.txt
```

### Option B: Docker (RecommandÃ© si Python 3.14+)
Si votre version de Python n'est pas encore supportÃ©e par TensorFlow (ex: Python 3.14), utilisez Docker pour un environnement stable.

```bash
# Construire et lancer la prÃ©paration des donnÃ©es
docker-compose -f docker-compose.ml.yml run training python -m ml.data_preparation

# Lancer l'entraÃ®nement pour le BÃ©tÃ©
docker-compose -f docker-compose.ml.yml run training python -m ml.training --target-language bÃ©tÃ© --epochs 100

# Lancer TensorBoard
docker-compose -f docker-compose.ml.yml up tensorboard
```

## ğŸ¯ Ã‰tapes pour EntraÃ®ner votre Premier ModÃ¨le

### Ã‰tape 1: Tester la PrÃ©paration des DonnÃ©es

```bash
# Tester la prÃ©paration des donnÃ©es pour toutes les langues
python -m ml.data_preparation
```

Cela va:
- âœ… Charger les donnÃ©es depuis `data/language.json`
- âœ… Augmenter le dataset (x5)
- âœ… CrÃ©er les vocabulaires
- âœ… GÃ©nÃ©rer les datasets TensorFlow

### Ã‰tape 2: EntraÃ®ner un ModÃ¨le (Commencer par BÃ©tÃ©)

```bash
# EntraÃ®ner le modÃ¨le pour le BÃ©tÃ© (recommandÃ© pour commencer)
python -m ml.training --target-language bÃ©tÃ© --epochs 50
```

**Options disponibles**:
- `--target-language`: Langue cible (bÃ©tÃ©, baoulÃ©, moorÃ©, agni)
- `--epochs`: Nombre d'epochs (dÃ©faut: 100)
- `--no-augment`: DÃ©sactiver l'augmentation de donnÃ©es
- `--learning-rate`: Learning rate (dÃ©faut: 0.001)

**DurÃ©e estimÃ©e**: 10-30 minutes selon votre machine

### Ã‰tape 3: Surveiller l'EntraÃ®nement avec TensorBoard

```bash
# Dans un autre terminal
tensorboard --logdir ml/logs
```

Ouvrez http://localhost:6006 pour voir:
- Courbes de loss
- Accuracy
- Learning rate
- Histogrammes des poids

### Ã‰tape 4: Ã‰valuer le ModÃ¨le

```bash
# Ã‰valuer sur des exemples prÃ©dÃ©finis
python -m ml.evaluation --target-language bÃ©tÃ© --examples-only

# Ã‰valuer sur le dataset de test complet
python -m ml.evaluation --target-language bÃ©tÃ©
```

### Ã‰tape 5: Tester l'IntÃ©gration dans l'API

```bash
# DÃ©marrer le serveur Flask
python app.py
```

Le service TensorFlow se chargera automatiquement au dÃ©marrage.

**Tester avec curl**:
```bash
curl -X POST http://localhost:5000/kumajala-api/v1/translate \
  -H "Content-Type: application/json" \
  -d '{"text": "bonjour", "targetLanguage": "bÃ©tÃ©"}'
```

## ğŸ“Š Structure des Fichiers GÃ©nÃ©rÃ©s

AprÃ¨s l'entraÃ®nement, vous aurez:

```
ml/
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ bÃ©tÃ©_model/          # ModÃ¨le SavedModel
â”‚   â”œâ”€â”€ bÃ©tÃ©_weights.h5      # Poids du modÃ¨le
â”‚   â”œâ”€â”€ vocab_fr.json        # Vocabulaire franÃ§ais
â”‚   â””â”€â”€ vocab_bÃ©tÃ©.json      # Vocabulaire bÃ©tÃ©
â”œâ”€â”€ logs/
â”‚   â””â”€â”€ bÃ©tÃ©_YYYYMMDD_HHMMSS/  # Logs TensorBoard
â””â”€â”€ checkpoints/
    â””â”€â”€ bÃ©tÃ©_YYYYMMDD_HHMMSS/  # Checkpoints d'entraÃ®nement
```

## ğŸ”„ StratÃ©gie de Fallback

L'API utilise maintenant une stratÃ©gie progressive:

1. **TensorFlow** (si confiance â‰¥ 0.7)
2. **Gemini** (si TensorFlow Ã©choue ou confiance faible)
3. **Database** (en dernier recours)

## ğŸ¨ EntraÃ®ner pour Toutes les Langues

```bash
# Script pour entraÃ®ner tous les modÃ¨les
for lang in bÃ©tÃ© baoulÃ© moorÃ© agni; do
  echo "EntraÃ®nement pour $lang..."
  python -m ml.training --target-language $lang --epochs 50
done
```

## ğŸ› RÃ©solution de ProblÃ¨mes

### Erreur: "ModÃ¨le non trouvÃ©"
- Assurez-vous d'avoir entraÃ®nÃ© le modÃ¨le d'abord
- VÃ©rifiez que le dossier `ml/models/<langue>_model` existe

### Erreur: "TensorFlow non disponible"
- VÃ©rifiez l'installation: `pip install tensorflow==2.15.0`
- Sur Windows, vous pourriez avoir besoin de Visual C++ Redistributable

### Performance lente
- Utilisez un GPU si disponible
- RÃ©duisez `BATCH_SIZE` dans `ml/config.py`
- RÃ©duisez `ENCODER_UNITS` et `DECODER_UNITS`

## ğŸ“ˆ AmÃ©liorer les RÃ©sultats

1. **Ajouter plus de donnÃ©es**:
   - Ã‰ditez `data/language.json`
   - Ajoutez plus de paires de traduction

2. **Augmenter les epochs**:
   ```bash
   python -m ml.training --target-language bÃ©tÃ© --epochs 200
   ```

3. **Ajuster les hyperparamÃ¨tres**:
   - Ã‰ditez `ml/config.py`
   - Modifiez `EMBEDDING_DIM`, `ENCODER_UNITS`, etc.

## ğŸ¯ Prochaines Ã‰tapes

- [ ] EntraÃ®ner les 4 modÃ¨les (bÃ©tÃ©, baoulÃ©, moorÃ©, agni)
- [ ] Collecter plus de donnÃ©es de traduction
- [ ] Tester avec des utilisateurs rÃ©els
- [ ] Optimiser les modÃ¨les (quantization, pruning)
- [ ] DÃ©ployer en production

## ğŸ’¡ Conseils

- **Commencez petit**: EntraÃ®nez d'abord avec 50 epochs pour tester
- **Surveillez TensorBoard**: VÃ©rifiez que la loss diminue
- **Testez rÃ©guliÃ¨rement**: Utilisez `--examples-only` pour des tests rapides
- **Sauvegardez vos modÃ¨les**: Les checkpoints sont dans `ml/checkpoints/`
